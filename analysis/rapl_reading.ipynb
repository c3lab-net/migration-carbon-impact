{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ccbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, argparse, glob\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import *\n",
    "from matplotlib_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_prefix(l):\n",
    "    \"Given a list of pathnames, returns the longest common leading component\"\n",
    "    if not l: return ''\n",
    "    s1 = min(l)\n",
    "    s2 = max(l)\n",
    "    for i, c in enumerate(s1):\n",
    "        if c != s2[i]:\n",
    "            return s1[:i]\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf_array(array, label, include_count = False, index=0, color=None):\n",
    "    x = sorted(array)\n",
    "    y = np.linspace(0., 1., len(array) + 1)[1:]\n",
    "    if include_count:\n",
    "        label += ' (%d)' % len(array)\n",
    "    if color is None:\n",
    "        color = get_next_color()\n",
    "    plt.plot(x, y, label=label, color=color, linestyle=get_linestyle(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f883331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(data_array, plot_axis=None, timestamp_column_name='timestamp', prefix=None, use_relative_time=False, color=None, index=0):\n",
    "    x = [entry[timestamp_column_name] for entry in data_array]\n",
    "    if use_relative_time:\n",
    "        start_time = x[0]\n",
    "        x = [(t - start_time).total_seconds() for t in x]\n",
    "    data_keys = []\n",
    "    for key in data_array[0].keys():\n",
    "        if key == timestamp_column_name:\n",
    "            continue\n",
    "        data_keys.append(key)\n",
    "    lines = []\n",
    "    for key in data_keys:\n",
    "        data_series = [entry[key] for entry in data_array]\n",
    "        label = ('%s - ' % prefix if prefix else '') + key\n",
    "        if plot_axis is None:\n",
    "            plot_axis = plt.gca()\n",
    "        line = plot_axis.plot(x, data_series, color=color, linestyle=get_linestyle(index), label=label)\n",
    "        index += 1\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rapl_data(rapl_log_file):\n",
    "    data_array = []\n",
    "    with open(rapl_log_file, 'r') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        column_names = csv_reader.fieldnames\n",
    "        required_columns = set(['timestamp', 'total_intel_energy', 'total_cpu_energy', 'total_dram_energy'])\n",
    "        assert [required_column in column_names for required_column in required_columns]\n",
    "        for row in csv_reader:\n",
    "            timestamp = datetime.fromisoformat(row['timestamp'])\n",
    "            total_intel_energy = float(row['total_intel_energy'])\n",
    "            total_cpu_energy = float(row['total_cpu_energy'])\n",
    "            total_dram_energy = float(row['total_dram_energy'])\n",
    "            data_array.append({\n",
    "                'timestamp': timestamp,\n",
    "                'total_intel_energy': total_intel_energy,\n",
    "    #             'total_cpu_energy': total_cpu_energy,\n",
    "    #             'total_dram_energy': total_dram_energy,\n",
    "            })\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_mem_usage_data(usage_log_file):\n",
    "    data_array = []\n",
    "    with open(usage_log_file, 'r') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        column_names = csv_reader.fieldnames\n",
    "        required_columns = set(['timestamp', 'cpu-user', 'cpu-kernel', 'cpu-idle', 'mem-used', 'mem-free'])\n",
    "        assert [required_column in column_names for required_column in required_columns]\n",
    "        for row in csv_reader:\n",
    "            timestamp = datetime.fromisoformat(row['timestamp'])\n",
    "            cpu_user = float(row['cpu-user'])\n",
    "            cpu_kernel = float(row['cpu-kernel'])\n",
    "            cpu_idle = float(row['cpu-idle'])\n",
    "            mem_used = float(row['mem-used'])\n",
    "            mem_free = float(row['mem-free'])\n",
    "            data_array.append({\n",
    "                'timestamp': timestamp,\n",
    "                'cpu': cpu_user + cpu_kernel,\n",
    "                # 'mem': mem_used / (mem_used + mem_free),\n",
    "                # 'cpu-user': cpu_user,\n",
    "                # 'cpu-kernel': cpu_kernel,\n",
    "                # 'cpu-idle': cpu_idle,\n",
    "                # 'mem-used': mem_used,\n",
    "                # 'mem-free': mem_free,\n",
    "            })\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array is a list of dicts, each of which has 'timestamp', 'total_intel_energy', ...\n",
    "# it's already sorted by timestamp\n",
    "def get_energy_stats(data_array):\n",
    "    assert len(data_array) > 2, \"Time series is too short\"\n",
    "    l_timestamp = np.array([entry['timestamp'] for entry in data_array])\n",
    "    delta_timestamps = [int(delta.total_seconds()) for delta in np.diff(l_timestamp, n=1)]\n",
    "    sample_interval_s = delta_timestamps[0]\n",
    "    assert all(delta == sample_interval_s for delta in delta_timestamps)\n",
    "#     print('Sample interval: %ds' % sample_interval_s)\n",
    "\n",
    "    # detect idle power draw\n",
    "    l_power = np.array([entry['total_intel_energy']/sample_interval_s for entry in data_array])\n",
    "#     print(l_power)\n",
    "    delta_power = np.diff(l_power, n=1)\n",
    "#     print(delta_power)\n",
    "    assert len(l_power) == len(delta_power) + 1\n",
    "    POWER_DIFF_THRESHOLD = 1\n",
    "    IDLE_POWER_STD_THRESHOLD = 0.01\n",
    "    index_workload_start = np.argmax(delta_power > POWER_DIFF_THRESHOLD)\n",
    "    index_workload_end = len(delta_power) - np.argmax(delta_power[::-1] < -POWER_DIFF_THRESHOLD)\n",
    "    l_power_idle_before = l_power[:index_workload_start]\n",
    "    l_power_workload = l_power[index_workload_start:index_workload_end]\n",
    "    l_power_idle_after = l_power[index_workload_end:]\n",
    "    avg_power_idle_before = np.average(l_power_idle_before)\n",
    "    std_power_idle_before = np.std(l_power_idle_before)\n",
    "    avg_power_idle_after = np.average(l_power_idle_after)\n",
    "    std_power_idle_after = np.std(l_power_idle_after)\n",
    "#     print(avg_power_idle_before, std_power_idle_before, avg_power_idle_after, std_power_idle_after)\n",
    "\n",
    "    assert std_power_idle_before / avg_power_idle_before < IDLE_POWER_STD_THRESHOLD, \"Idle power std is too high\"\n",
    "    assert std_power_idle_after / avg_power_idle_after < IDLE_POWER_STD_THRESHOLD, \"Idle power std is too high\"\n",
    "    \n",
    "    # \"Idle power before/after difference is too high\"\n",
    "    avg_power_idle = np.average([avg_power_idle_before, avg_power_idle_after])\n",
    "    if np.abs(avg_power_idle_before - avg_power_idle_after) > POWER_DIFF_THRESHOLD:\n",
    "        avg_power_idle = avg_power_idle_before\n",
    "\n",
    "#     print('Workload duration: %ds' % len(l_power_workload) * sample_interval_s)\n",
    "#     print('Idle power: %.fW' % (avg_power_idle / sample_interval_s))\n",
    "    return {\n",
    "        'duration': len(l_power_workload) * sample_interval_s,\n",
    "        'start_index': index_workload_start,\n",
    "        'total_energy': np.sum(l_power_workload),\n",
    "        'delta_energy': np.sum(l_power_workload) - len(l_power_workload) * avg_power_idle,\n",
    "        'sample_interval_s': sample_interval_s,\n",
    "        'idle_power': avg_power_idle,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.realpath('../data/video-transcoding/logs/')\n",
    "\n",
    "l_sample_interval_s = []\n",
    "for (rapl_log_file, cpu_mem_usage_log_file) in [\n",
    "        ('combined/ffmpeg.rapl.csv', 'combined/ffmpeg.usage.csv'),\n",
    "        ('combined/scp.src.rapl.csv', 'combined/scp.src.usage.csv'),\n",
    "        ('combined/scp.dst.rapl.csv', 'combined/scp.dst.usage.csv'),\n",
    "        # 'ffmpeg-Rain.csv'\n",
    "        # 'ffmpeg-Rain-10x.csv',\n",
    "        # 'ffmpeg-Rain.data-copy.1G.csv',\n",
    "        # 'ffmpeg.youtube-wnhvanMdx4s.720p.csv',\n",
    "        # 'ffmpeg-Rain.data-copy.100G.csv',\n",
    "        # 'spark-wordcount-short.csv',\n",
    "        # 'spark-wordcount-long.csv',\n",
    "        # 'spark-wordcount-long.data-copy.1G.csv',\n",
    "        # 'spark-wordcount-long.data-copy.100G.csv',\n",
    "    ]:\n",
    "    name = common_prefix([rapl_log_file, cpu_mem_usage_log_file])\n",
    "    name = name.split('/')[-1].rstrip('.')\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    plot_lines = []\n",
    "    energy_data_array = get_rapl_data(os.path.join(ROOT_DIR, rapl_log_file))\n",
    "    plot_lines += plot_timeseries(energy_data_array, plot_axis=ax1, prefix=\"RAPL\", use_relative_time=False, color='orange')\n",
    "    energy_stats = get_energy_stats(energy_data_array)\n",
    "    l_sample_interval_s.append(energy_stats['sample_interval_s'])\n",
    "    print('Workload: %s' % rapl_log_file)\n",
    "    print('Duration: %.fs' % energy_stats['duration'])\n",
    "    print('Total energy: %.fJ' % energy_stats['total_energy'])\n",
    "    print('Delta energy: %.fJ' % energy_stats['delta_energy'])\n",
    "    cpu_mem_usage_data_array = get_cpu_mem_usage_data(os.path.join(ROOT_DIR, cpu_mem_usage_log_file))\n",
    "    plot_lines += plot_timeseries(cpu_mem_usage_data_array, plot_axis=ax2, prefix=\"Usage\", use_relative_time=False, color='blue', index=0)\n",
    "    # plot_labels = [line.get_label() for line in plot_lines]\n",
    "    # plot_labels = ax1.lines + ax2.lines\n",
    "    # ax1.legend(plot_lines, plot_labels)\n",
    "    # plt.xlim(0, 20)\n",
    "    # plt.ylim(105, 115)\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Power (W)', color='orange')\n",
    "    ax2.set_ylabel('Utilization (%)', color='blue')\n",
    "    ax1.set_ylim(100, 125)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    plt.grid()\n",
    "    fig.legend(loc='upper left', bbox_to_anchor=(0.15, 0.88))\n",
    "    # ax2.legend(loc='lower center')\n",
    "    plt.title('Workload: %s' % name)\n",
    "    # plt.savefig('rapl-ffmpeg-Rain.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
