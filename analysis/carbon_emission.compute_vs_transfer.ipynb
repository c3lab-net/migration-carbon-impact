{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from matplotlib_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "\n",
    "metadata = {\n",
    "    'emission_rates': {\n",
    "        'ylabel': 'gCO2/s',\n",
    "        'title': 'Instantaneous emission rates'\n",
    "    },\n",
    "    'emission_integral': {\n",
    "        'ylabel': 'gCO2',\n",
    "        'title': 'Emission integral over its duration'\n",
    "    },\n",
    "}\n",
    "\n",
    "d_timing_labels = {\n",
    "    \"input_transfer_start\": \"Input transfer\",\n",
    "    # \"input_transfer_start\": \"Start of input transfer\",\n",
    "    # \"input_transfer_end\": \"End of input transfer\",\n",
    "    \"compute_start\": \"Compute\",\n",
    "    # \"compute_start\": \"Start of compute\",\n",
    "    # \"compute_end\": \"End of compute\",\n",
    "    \"output_transfer_start\": \"Output transfer\",\n",
    "    # \"output_transfer_start\": \"Start of output transfer\",\n",
    "    # \"output_transfer_end\": \"End of output transfer\",\n",
    "}\n",
    "\n",
    "d_events = {\n",
    "    'input_transfer': {\n",
    "        'interval_keys': (\"input_transfer_start\", \"input_transfer_end\"),\n",
    "        'label': 'Input transfer',\n",
    "    },\n",
    "    'compute': {\n",
    "        'interval_keys': (\"compute_start\", \"compute_end\"),\n",
    "        'label': 'Compute',\n",
    "    },\n",
    "    'output_transfer': {\n",
    "        'interval_keys': (\"output_transfer_start\", \"output_transfer_end\"),\n",
    "        'label': 'Output transfer',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value(data_details: dict, series_name: str):\n",
    "    max_value = 0\n",
    "    for region in data_details:\n",
    "        compute_data = data_details[region][series_name][\"compute\"]\n",
    "        transfer_data = data_details[region][series_name][\"transfer\"]\n",
    "        max_value = max(max_value, max(compute_data.values(), default=0), max(transfer_data.values(), default=0))\n",
    "    return max_value\n",
    "\n",
    "def resample_timeseries(df: pd.DataFrame, interval: str):\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "    df.set_index(\"Timestamp\", inplace=True)\n",
    "    df_resampled = df.resample(interval).ffill().reset_index()\n",
    "    return df_resampled\n",
    "\n",
    "def create_dataframe_for_plotting(timeseries: dict[str, float], min_start: datetime, max_end: datetime) -> pd.DataFrame:\n",
    "    \"\"\"Convert a time series data to a dataframe, while removing out of bound timestamps.\n",
    "    \n",
    "        Args:\n",
    "            timeseries: A dictionary of timestamp strings and values.\n",
    "            min_start: The minimum cutoff time for the timeseries.\n",
    "            max_end: The maximum cutoff time for the timeseries.\n",
    "    \"\"\"\n",
    "    timeseries_in_datatime = {datetime.fromisoformat(key): value for key, value in timeseries.items()}\n",
    "    df = pd.DataFrame(list(timeseries_in_datatime.items()), columns=[\"Timestamp\", \"Value\"])\n",
    "    if df.empty:\n",
    "        return df\n",
    "    resampled = resample_timeseries(df, \"30s\")\n",
    "    mask = (resampled[\"Timestamp\"] >= pd.to_datetime(min_start)) & (resampled[\"Timestamp\"] <= pd.to_datetime(max_end))\n",
    "    return resampled[mask]\n",
    "\n",
    "def add_timing(ax, name: str, time: pd.Timestamp, max_value: float, color: str):\n",
    "    if 'start' in name:\n",
    "        ax.vlines(time, ymin=0, ymax=max_value, color='gray', alpha=0.5, linestyles=\"solid\" if 'compute' in name else \"dashed\")\n",
    "        if 'input' in name:\n",
    "            ha = 'right'\n",
    "            rotation = -30\n",
    "        elif 'output' in name:\n",
    "            ha = 'left'\n",
    "            rotation = 30\n",
    "        else:\n",
    "            ha = 'center'\n",
    "            rotation = 0\n",
    "        ax.text(time, max_value, d_timing_labels[name], color=color, alpha=0.95, ha=ha, va=\"bottom\", rotation=rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_payload = {\n",
    "    \"runtime\": 391,\n",
    "    \"schedule\": {\n",
    "        \"type\": \"onetime\",\n",
    "        \"start_time\": \"2023-05-24T22:00:00+00:00\",\n",
    "        \"max_delay\": 19800\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"input_size_gb\": 1.2,\n",
    "        \"output_size_gb\": 0.25\n",
    "    },\n",
    "    \"candidate_locations\": [\n",
    "        {\n",
    "            \"id\": \"Azure:eastus\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"Azure:westus\"\n",
    "        }\n",
    "    ],\n",
    "    \"use_prediction\": False,\n",
    "    \"carbon_data_source\": \"c3lab\",\n",
    "    \"watts_per_core\": 2.9,\n",
    "    \"core_count\": 80,\n",
    "    \"original_location\": \"Azure:eastus\",\n",
    "    \"optimize_carbon\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARBON_API_URL='http://localhost:8082/carbon-aware-scheduler/'\n",
    "\n",
    "# Make the API call\n",
    "response = requests.get(CARBON_API_URL, json=request_payload)\n",
    "\n",
    "# Check if the API call was successful (status code 200)\n",
    "assert response.ok, f\"Error: API call failed with status code {response.status_code}\"\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "d_region_colors = {}\n",
    "for region in data['details']:\n",
    "    d_region_colors[region] = get_next_color()\n",
    "\n",
    "# Extract emission integral data\n",
    "for (ax, series_name) in zip(axes, [\"emission_rates\", \"emission_integral\"]):\n",
    "    # # Get max value for y-axis\n",
    "    # max_y_value = get_max_value(data['details'], series_name)\n",
    "\n",
    "    for region in data['details']:\n",
    "        compute_data = data[\"details\"][region][series_name][\"compute\"]\n",
    "        transfer_data = data[\"details\"][region][series_name][\"transfer\"]\n",
    "        timings = data[\"details\"][region]['timings'][0] # Assume single occurence per job\n",
    "        min_start = datetime.fromisoformat(timings['min_start'])\n",
    "        max_end = datetime.fromisoformat(timings['max_end'])\n",
    "\n",
    "        # Convert timestamp strings to datetime objects\n",
    "        compute_df = create_dataframe_for_plotting(compute_data, min_start, max_end)\n",
    "        transfer_df = create_dataframe_for_plotting(transfer_data, min_start, max_end)\n",
    "\n",
    "        # Plot timeseries data as step functions\n",
    "        color = d_region_colors[region]\n",
    "        ax.step(compute_df[\"Timestamp\"], compute_df[\"Value\"], label=f\"{region} - Compute\", color=color, linestyle=\"solid\")\n",
    "        if not transfer_df.empty:\n",
    "            ax.step(transfer_df[\"Timestamp\"], transfer_df[\"Value\"], label=f\"{region} - Transfer\", color=color, linestyle=\"dashed\")\n",
    "\n",
    "        # Add events based on the timings\n",
    "        max_y_value = max(compute_df[\"Value\"].max(), transfer_df[\"Value\"].max())\n",
    "        for event in d_events:\n",
    "            df = compute_df if event == 'compute' else transfer_df\n",
    "            if df.empty:\n",
    "                continue\n",
    "            # Vertical lines and texts\n",
    "            for name in d_events[event]['interval_keys']:\n",
    "                add_timing(ax, name, pd.to_datetime(timings[name]), max_y_value, color=d_region_colors[region])\n",
    "            # Fill area for events under the curve\n",
    "            (start_event, end_event) = d_events[event]['interval_keys']\n",
    "            ax.fill_between(x=df['Timestamp'], y1=df['Value'], where=((df['Timestamp'] >= pd.to_datetime(timings[start_event])) & (df['Timestamp'] <= pd.to_datetime(timings[end_event]))), color=color, alpha=0.5)\n",
    "\n",
    "    ax.set_title(metadata[series_name]['title'])\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(metadata[series_name]['ylabel'])\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
