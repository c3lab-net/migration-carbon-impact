{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "# import requests_cache\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import random\n",
    "import math\n",
    "import bisect\n",
    "import arrow\n",
    "import pytz\n",
    "from datetime import datetime, date, timedelta\n",
    "from timezonefinder import TimezoneFinder\n",
    "from matplotlib import pyplot as plt, dates\n",
    "from matplotlib.ticker import *\n",
    "from carbon_api_client import *\n",
    "from matplotlib_helper import *\n",
    "from typing import List, Any\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_utc_time_of_day = True\n",
    "enable_savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests_cache.install_cache('http_cache', backend='filesystem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "M_PUBLIC_CLOUD_LOCATION = {\n",
    "    ('AWS', 'us-west-1'): (37.00578, -121.56828),\n",
    "    ('AWS', 'us-west-2'): (45.840410, -119.289460),\n",
    "    ('AWS', 'us-east-1'): (39.983334, -82.983330),\n",
    "    ('AWS', 'us-east-2'): (39.040283, -77.485165),\n",
    "    # Not needed as Azure carbon API relies on region name instead of geocoordinates\n",
    "    # ('Azure', 'eastus'):            (37.3719, -79.8164),\n",
    "    # ('Azure', 'eastus2'):           (36.6681, -78.3889),\n",
    "    # ('Azure', 'southcentralus'):    (29.4167, -98.5),\n",
    "    # ('Azure', 'westus2'):           (47.233, -119.852),\n",
    "    # ('Azure', 'westus3'):           (33.448376, -112.074036),\n",
    "    # ('Azure', 'centralus'):         (41.5908, -93.6208),\n",
    "    # ('Azure', 'eastus2euap'):       (36.6681, -78.3889),\n",
    "    # ('Azure', 'northcentralus'):    (41.8819, -87.6278),\n",
    "    # ('Azure', 'westus'):            (37.783, -122.417),\n",
    "    # ('Azure', 'centraluseuap'):     (41.5908, -93.6208),\n",
    "    # ('Azure', 'westcentralus'):     (40.890, -110.234),\n",
    "}\n",
    "def get_location_for_public_cloud(cloud_vendor, region):\n",
    "    '''Looks up the GPS coordinate for public cloud region.'''\n",
    "    if (cloud_vendor, region) in M_PUBLIC_CLOUD_LOCATION:\n",
    "        return M_PUBLIC_CLOUD_LOCATION[(cloud_vendor, region)]\n",
    "    else:\n",
    "        return (math.nan, math.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US/Canada\n",
    "azure_regions_americas = [\n",
    "    'westus',\n",
    "    'westus2',\n",
    "    'westcentralus',\n",
    "    'westus3',\n",
    "    'eastus',\n",
    "    'centralus',\n",
    "    'southcentralus',\n",
    "    # 'canadacentral',\n",
    "    # 'canadaeast',\n",
    "]\n",
    "\n",
    "# Europe\n",
    "azure_regions_europe = [\n",
    "    'uksouth',\n",
    "    'francecentral',\n",
    "    'germanywestcentral',\n",
    "    'northeurope',\n",
    "    'norwayeast',\n",
    "    'swedencentral',\n",
    "    'westeurope',\n",
    "]\n",
    "\n",
    "# Australia\n",
    "azure_regions_aus = [\n",
    "    'australiaeast',\n",
    "    'australiasoutheast',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_azure_regions_to_isos = {\n",
    "    # US/Canada\n",
    "    'westus': 'CAISO_NORTH',\n",
    "    'westus2': 'GCPD',\n",
    "    'westcentralus': 'PACE',\n",
    "    'westus3': 'AZPS',\n",
    "    'eastus': 'PJM_ROANOKE',\n",
    "    'centralus': 'MISO_MASON_CITY',\n",
    "    'southcentralus': 'ERCOT_SANANTONIO',\n",
    "    'canadacentral': 'IESO_NORTH',\n",
    "    'canadaeast': 'HQ',\n",
    "    # Europe\n",
    "    'uksouth': 'UK',\n",
    "    'francecentral': 'FR',\n",
    "    'germanywestcentral': 'DE',\n",
    "    'northeurope': 'IE',\n",
    "    'norwayeast': 'NO',\n",
    "    'swedencentral': 'SE',\n",
    "    'westeurope': 'NL',\n",
    "    # Australia\n",
    "    'australiaeast': 'NEM_NSW',\n",
    "    'australiasoutheast': 'NEM_VIC',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_count = 0\n",
    "\n",
    "def plot_timeseries(data_array, plot_axis=None, timestamp_column_name='timestamp', prefix=None, use_relative_time=False, color=None, index=0):\n",
    "    # global run_count\n",
    "    data_array = [asdict(entry) for entry in data_array]\n",
    "    x = [entry[timestamp_column_name] for entry in data_array]\n",
    "\n",
    "    # timestamp_deltas = np.diff(x)\n",
    "    # values, counts = np.unique(timestamp_deltas, return_counts=True)\n",
    "    # print(values, counts)\n",
    "\n",
    "    if use_relative_time:\n",
    "        start_time = x[0]\n",
    "        x = [(t - start_time).total_seconds() for t in x]\n",
    "    data_keys = []\n",
    "    for key in data_array[0].keys():\n",
    "        if key == timestamp_column_name:\n",
    "            continue\n",
    "        data_keys.append(key)\n",
    "    lines = []\n",
    "    for key in data_keys:\n",
    "        data_series = [entry[key] for entry in data_array]\n",
    "        label = (('%s - ' % prefix if prefix else '') + key) if len(data_keys) > 1 else (prefix if prefix else '')\n",
    "        if plot_axis is None:\n",
    "            plot_axis = plt.gca()\n",
    "        line = plot_axis.plot(x, data_series, color=color, linestyle=get_linestyle(index), label=label, marker=None)\n",
    "        # if run_count == 0:\n",
    "        #     plot_axis.fill_between(x, y1=data_series, where=[True if len(x)*17.5/24 < i < len(x)*20.5/24 else False for i in range(len(x))], alpha=0.2)\n",
    "        #     run_count += 1\n",
    "        tzinfo = x[0].tzinfo\n",
    "        plot_axis.xaxis_date(tz=tzinfo)\n",
    "        index += 1\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pd_timeseries(series: pd.Series, plot_axis=None, prefix=None, use_relative_time=False, color=None, index=0):\n",
    "    x = [ts.to_pydatetime() for ts in series.index.tolist()]\n",
    "    y = series.values\n",
    "    if use_relative_time:\n",
    "        start_time = x[0]\n",
    "        x = [(t - start_time).total_seconds() for t in x]\n",
    "    label = prefix if prefix else ''\n",
    "    if plot_axis is None:\n",
    "        plot_axis = plt.gca()\n",
    "    return plot_axis.plot(x, y, color=color, linestyle=get_linestyle(index), label=label, marker=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def call_gsf_carbon_api(cloud_vendor: str, region: str, start: arrow.Arrow, end: arrow.Arrow) -> CarbonIntensityData:\n",
    "    url_get_carbon_intensity = 'https://carbon-aware-api.azurewebsites.net/emissions/bylocations'\n",
    "    response = requests.get(url_get_carbon_intensity, params={\n",
    "        'location': [region],\n",
    "        'time': start,\n",
    "        'toTime': end,\n",
    "    })\n",
    "    assert response.ok, \"GSF carbon intensity lookup failed (%d): %s\" % (response.status_code, response.text)\n",
    "    response_json = response.json()\n",
    "\n",
    "    locations = set()\n",
    "    timeseries = []\n",
    "    for entry in response_json:\n",
    "        locations.add(entry['location'])\n",
    "        timestamp = arrow.get(entry['time']).datetime\n",
    "        carbon_intensity = float(entry['rating']) / 2.2 # lb/MWh -> g/kWh\n",
    "        duration = entry['duration']\n",
    "        timeseries.append(TimestampdValue(timestamp, carbon_intensity))\n",
    "    ds = create_pd_series([e.timestamp for e in timeseries], [e.value for e in timeseries])\n",
    "    iso = ','.join(locations)\n",
    "\n",
    "    return CarbonIntensityData(cloud_vendor, region, iso, timeseries, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_carbon_intensity_data(cloud_vendor, region, date:date = None, timerange:timedelta = timedelta(weeks=1), use_utc_time_of_day = True) -> CarbonIntensityData:\n",
    "    print(cloud_vendor, region)\n",
    "    (latitude, longitude) = get_location_for_public_cloud(cloud_vendor, region)\n",
    "    if date is None:\n",
    "        date = arrow.get().shift(weeks=-1).date()\n",
    "    if use_utc_time_of_day:\n",
    "        timezone = pytz.UTC\n",
    "    else:\n",
    "        timezone_str = TimezoneFinder().timezone_at(lng=longitude, lat=latitude)\n",
    "        timezone = pytz.timezone(timezone_str)\n",
    "    date = arrow.get(date, tzinfo=timezone)\n",
    "    # print(timezone_str, date, file=sys.stderr)\n",
    "    if cloud_vendor == 'AWS':\n",
    "        (latitude, longitude) = get_location_for_public_cloud(cloud_vendor, region)\n",
    "        ci_data = call_sysnet_carbon_intensity_api(latitude, longitude, date, date + timerange)\n",
    "        ci_data.cloud_vendor = cloud_vendor\n",
    "        ci_data.region = region\n",
    "        return ci_data\n",
    "    elif cloud_vendor == 'Azure':\n",
    "        return call_gsf_carbon_api(cloud_vendor, region, date, date.shift(minutes=-1) + timerange)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported region {cloud_vendor}:{region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_carbon_intensity_stats(l_time_series: List[TimestampdValue]):\n",
    "    l_carbon_intensity = [e.value for e in l_time_series]\n",
    "    print('Avg/Min/Max carbon intensity: %.2f/%.2f/%.2f' % (\n",
    "        np.mean(l_carbon_intensity),\n",
    "        np.min(l_carbon_intensity),\n",
    "        np.max(l_carbon_intensity),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_overlap_diff_of_carbon_intensities(time_series_1: pd.Series, time_series_2: pd.Series) -> List[float]:\n",
    "    s1_timestamps = [e.timestamp for e in time_series_1]\n",
    "    s2_timestamps = [e.timestamp for e in time_series_2]\n",
    "    union_timestamps = sorted(list(set(s1_timestamps).union(s2_timestamps)))\n",
    "    # Same index as common_timestamps\n",
    "    l1_carbon_intensity = []\n",
    "    l2_carbon_intensity = []\n",
    "    l_diff_carbon_intensity = []\n",
    "    for index in range(len(union_timestamps)):\n",
    "        curr_timestamp = union_timestamps[index]\n",
    "        if curr_timestamp in s1_timestamps:\n",
    "            index1 = s1_timestamps.index(curr_timestamp)\n",
    "        else:   # Find the previous timestamp and use that\n",
    "            index1 = max(bisect.bisect(s1_timestamps, curr_timestamp) - 1, 0)\n",
    "        if curr_timestamp in s2_timestamps:\n",
    "            index2 = s2_timestamps.index(curr_timestamp)\n",
    "        else:\n",
    "            index2 = max(bisect.bisect(s2_timestamps, curr_timestamp) - 1, 0)\n",
    "        carbon_intensity1 = time_series_1[index1].value\n",
    "        carbon_intensity2 = time_series_2[index2].value\n",
    "        l1_carbon_intensity.append(carbon_intensity1)\n",
    "        l2_carbon_intensity.append(carbon_intensity2)\n",
    "        l_diff_carbon_intensity.append(carbon_intensity2 - carbon_intensity1)\n",
    "    return l_diff_carbon_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_overlap_interval_of_carbon_intensities(time_series_1: List[TimestampdValue], time_series_2: List[TimestampdValue]) -> \\\n",
    "        List[tuple[datetime, datetime]]:\n",
    "    \"\"\"Find the intervals where carbon intensity of the first time series drops below the second.\"\"\"\n",
    "    print(\"Finding overlap in intervals\")\n",
    "    s1_timestamps = sorted([e.timestamp for e in time_series_1])\n",
    "    s2_timestamps = sorted([e.timestamp for e in time_series_2])\n",
    "    union_timestamps = sorted(list(set(s1_timestamps).union(s2_timestamps)))\n",
    "    # Same index as common_timestamps\n",
    "    l1_carbon_intensity: List[float] = []\n",
    "    l2_carbon_intensity: List[float] = []\n",
    "    overlap_intervals: List[tuple[datetime, datetime]] = []\n",
    "    interval_start_index = None\n",
    "    for index in range(len(union_timestamps)):\n",
    "        curr_timestamp = union_timestamps[index]\n",
    "        index1 = max(bisect.bisect(s1_timestamps, curr_timestamp) - 1, 0)\n",
    "        index2 = max(bisect.bisect(s2_timestamps, curr_timestamp) - 1, 0)\n",
    "        carbon_intensity1 = time_series_1[index1].value\n",
    "        carbon_intensity2 = time_series_2[index2].value\n",
    "        l1_carbon_intensity.append(carbon_intensity1)\n",
    "        l2_carbon_intensity.append(carbon_intensity2)\n",
    "        if carbon_intensity1 <= carbon_intensity2:\n",
    "            if interval_start_index is None:\n",
    "                interval_start_index = index\n",
    "        else:\n",
    "            if interval_start_index is not None:\n",
    "                timestamp_start = union_timestamps[interval_start_index]\n",
    "                timestamp_end = union_timestamps[index]\n",
    "                overlap_intervals.append((timestamp_start, timestamp_end))\n",
    "                interval_start_index = None\n",
    "    print(\"done\")\n",
    "    return overlap_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_overlap_interval_cdf(overlap_intervals: List[tuple[datetime, datetime]], label: str) -> None:\n",
    "    interval_deltas = [(interval[1] - interval[0]) for interval in overlap_intervals]\n",
    "    interval_in_hours = [delta.total_seconds() / timedelta(hours=1).total_seconds() for delta in interval_deltas]\n",
    "    plot_cdf_array(interval_in_hours, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_cloud_region_name(cloud_region: tuple[str, str], iso: str) -> str:\n",
    "    \"\"\"Format the name for a cloud region, including its electricity-sourcing ISO.\"\"\"\n",
    "    return f'{cloud_region[0]} {cloud_region[1]} ({iso})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pull_carbon_intensity_data(cloud_vendor_and_regions: list[tuple], start_date: datetime, end_date: datetime):\n",
    "    print(f'Pulling carbon intensity data in range [{start_date.strftime(\"%Y-%m-%d\")}, {end_date.strftime(\"%Y-%m-%d\")}]')\n",
    "    window_size = end_date - start_date\n",
    "    all_region_time_series_data = {}\n",
    "    for (cloud_vendor, region) in cloud_vendor_and_regions:\n",
    "        carbon_intensity_data = get_carbon_intensity_data(cloud_vendor, region, date=start_date, timerange=window_size, use_utc_time_of_day=use_utc_time_of_day)\n",
    "        carbon_intensity_data.set_timeseries_interval('5min')\n",
    "\n",
    "        all_region_time_series_data[(cloud_vendor, region)] = carbon_intensity_data\n",
    "        time_series_data = carbon_intensity_data.timeseries\n",
    "        print_carbon_intensity_stats(time_series_data)\n",
    "    return all_region_time_series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_carbon_intensity_time_series(all_region_time_series_data: dict[tuple, CarbonIntensityData], start_date: datetime, end_date: datetime):\n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    plt.figure(figsize=(12, 4.8))\n",
    "    for (cloud_vendor, region) in all_region_time_series_data:\n",
    "        print(f'Region: {cloud_vendor}, {region}')\n",
    "        carbon_intensity_data = all_region_time_series_data[(cloud_vendor, region)]\n",
    "        time_series_data = list(filter(\n",
    "            lambda x: start_date < x.timestamp < end_date,\n",
    "            carbon_intensity_data.timeseries\n",
    "        ))\n",
    "        # sampled_data = sorted(random.sample(time_series_data, min(len(time_series_data), 1000)), key=lambda e: e['timestamp'])\n",
    "        sampled_data = time_series_data\n",
    "        plot_timeseries(sampled_data, use_relative_time=False, prefix=f'{cloud_vendor} {region} ({carbon_intensity_data.iso})')\n",
    "    window_size = end_date - start_date\n",
    "    if window_size.total_seconds() == timedelta(days=1).total_seconds():\n",
    "        date_formatter_string = \"%H:%M\"\n",
    "        xlabel = f'Time of day ({\"UTC\" if use_utc_time_of_day else \"local\"})'\n",
    "    else:\n",
    "        date_formatter_string = \"%Y/%m/%d\"\n",
    "        xlabel = 'Date'\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter(date_formatter_string))\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Carbon intensity (gCO2/kWh)')\n",
    "    plt.title(f'{window_size.days}-day carbon intensity in [{start_date.strftime(\"%Y-%m-%d\")}, {end_date.strftime(\"%Y-%m-%d\")})')\n",
    "    # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=4)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.ylim(0, 400)\n",
    "    plt.tight_layout()\n",
    "    savefig_filename = 'carbon-intensity.timeseries.%s-%s.png' % (start_date.strftime(\"%Y%m%d\"), end_date.strftime(\"%Y%m%d\"))\n",
    "    if enable_savefig:\n",
    "        plt.savefig(savefig_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_carbon_intensity_overlap_cdf(all_region_time_series_data: dict[tuple, CarbonIntensityData], l_cloud_region_pairs: list[tuple[tuple, tuple]], start_date: datetime, end_date: datetime):\n",
    "    plt.figure()\n",
    "    # plt.figure(figsize=(5, 4))\n",
    "    for (cloud_region1, cloud_region2) in l_cloud_region_pairs:\n",
    "        carbon_data1 = all_region_time_series_data[cloud_region1]\n",
    "        carbon_data2 = all_region_time_series_data[cloud_region2]\n",
    "        region1_name = format_cloud_region_name(cloud_region1, carbon_data1.iso)\n",
    "        region2_name = format_cloud_region_name(cloud_region2, carbon_data2.iso)\n",
    "        overlap_intervals = find_overlap_interval_of_carbon_intensities(carbon_data1.timeseries,\n",
    "                                                                        carbon_data2.timeseries)\n",
    "        print(\"plotting CDF\")\n",
    "        plot_overlap_interval_cdf(overlap_intervals, f'{region1_name} < {region2_name}')\n",
    "        print(\"done\")\n",
    "    plt.xlabel('Overlap (hours)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.title('Carbon intensity overlap in [%s,%s)' % (start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "    plt.tight_layout()\n",
    "    savefig_filename = 'carbon-intensity.overlap.%s-%s.png' % (start_date.strftime(\"%Y%m%d\"), end_date.strftime(\"%Y%m%d\"))\n",
    "    if enable_savefig:\n",
    "        plt.savefig(savefig_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_vendor_and_regions = []\n",
    "l_cloud_region_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_vendor_and_regions = list(map(lambda r: ('Azure', r), azure_regions_americas[0:2]))\n",
    "# cloud_vendor_and_regions = list(map(lambda r: ('Azure', r), azure_regions_americas + azure_regions_europe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "cloud_vendor_and_regions = [\n",
    "    ('AWS', 'us-west-1'),\n",
    "    ('AWS', 'us-west-2'),\n",
    "    ('AWS', 'us-east-1'),\n",
    "    # AWS us-east-2 uses the same ISO as us-east-1\n",
    "    # ('AWS', 'us-east-2'),\n",
    "]\n",
    "\n",
    "l_cloud_region_pairs = [\n",
    "    (('AWS', 'us-east-1'), ('AWS', 'us-west-1')),\n",
    "    (('AWS', 'us-east-1'), ('AWS', 'us-west-2'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# cloud_vendor_and_regions = list(map(lambda r: ('Azure', r), azure_regions_americas))\n",
    "# cloud_vendor_and_regions = list(map(lambda r: ('Azure', r), azure_regions_europe))\n",
    "\n",
    "cloud_vendor_and_regions = list(map(lambda r: ('Azure', r), [\n",
    "    'centralus',\n",
    "    'westus',\n",
    "    # 'germanywestcentral', # too high\n",
    "    # 'francecentral',  # too low\n",
    "    'uksouth',\n",
    "    # 'northeurope',\n",
    "]))\n",
    "\n",
    "l_cloud_region_pairs = [\n",
    "    (('Azure', 'eastus'), ('Azure', 'uksouth')),\n",
    "    (('Azure', 'eastus'), ('Azure', 'westus')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = timedelta(days=30)\n",
    "# base_start_date = datetime.utcnow().date()\n",
    "base_start_date = datetime(2022, 10, 1, tzinfo=tz.UTC)\n",
    "d_region_time_series_data_by_offset = {}\n",
    "for offset in range(12):\n",
    "    start_date = arrow.get(base_start_date) + (window_size * -(1 + offset))\n",
    "    end_date = start_date + window_size\n",
    "    d_region_time_series_data_by_offset[(start_date, end_date)] = pull_carbon_intensity_data(cloud_vendor_and_regions, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date, end_date in d_region_time_series_data_by_offset:\n",
    "    all_region_time_series_data = d_region_time_series_data_by_offset[(start_date, end_date)]\n",
    "    plot_carbon_intensity_time_series(all_region_time_series_data, start_date, end_date)\n",
    "\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "for start_date, end_date in d_region_time_series_data_by_offset:\n",
    "    all_region_time_series_data = d_region_time_series_data_by_offset[(start_date, end_date)]\n",
    "    plot_carbon_intensity_overlap_cdf(all_region_time_series_data, l_cloud_region_pairs, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_carbon_intensity_data(ci1: CarbonIntensityData, ci2: CarbonIntensityData, diff_timeseries: list[TimestampdValue], diff_ds: pd.Series) -> CarbonIntensityData:\n",
    "    diff_region_name = f'({ci1.cloud_vendor}:{ci1.region} - {ci2.cloud_vendor}:{ci2.region})'\n",
    "    diff_iso_name = f'{ci1.iso} - {ci2.iso}'\n",
    "    return CarbonIntensityData('diff', diff_region_name, diff_iso_name, diff_timeseries, diff_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_carbon_intensity(ci1: CarbonIntensityData, ci2: CarbonIntensityData) -> CarbonIntensityData:\n",
    "    diff_timeseries = []\n",
    "    ds1 = ci1.timeseries_pd\n",
    "    ds2 = ci2.timeseries_pd\n",
    "    combined_index = sorted(set(ds1.index.tolist() + ds2.index.tolist()))\n",
    "    ds1 = ds1.reindex(combined_index, method='ffill')\n",
    "    ds2 = ds2.reindex(combined_index, method='ffill')\n",
    "    diff_ds = ds1 - ds2\n",
    "    diff_ds.dropna()\n",
    "    diff_timeseries = CarbonIntensityData.create_timeseries_from_pd(diff_ds)\n",
    "    diff_region_name = f'({ci1.cloud_vendor}:{ci1.region} - {ci2.cloud_vendor}:{ci2.region})'\n",
    "    diff_iso_name = f'{ci1.iso} - {ci2.iso}'\n",
    "    return create_diff_carbon_intensity_data(ci1, ci2, diff_timeseries, diff_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date, end_date in d_region_time_series_data_by_offset:\n",
    "    all_region_time_series_data = d_region_time_series_data_by_offset[(start_date, end_date)]\n",
    "    diff_time_series_data = {}\n",
    "    for cr1, cr2 in l_cloud_region_pairs:\n",
    "        ci_data_diff = get_diff_carbon_intensity(\n",
    "            all_region_time_series_data[cr1],\n",
    "            all_region_time_series_data[cr2]\n",
    "        )\n",
    "        diff_time_series_data[(ci_data_diff.cloud_vendor, ci_data_diff.region)] = ci_data_diff\n",
    "    plot_end_date = start_date + timedelta(days=1)\n",
    "    # plot_carbon_intensity_time_series(all_region_time_series_data, start_date, plot_end_date)\n",
    "    plot_carbon_intensity_time_series(diff_time_series_data, start_date, plot_end_date)\n",
    "    plt.axhline(y=0, color='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_region_time_series_data_by_offset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c686f18b94c7ac93143553ca22fc47dddb45e62f4fa825973de80c268de3ec5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
