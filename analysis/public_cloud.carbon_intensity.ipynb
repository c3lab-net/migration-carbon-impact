{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import random\n",
    "import math\n",
    "import bisect\n",
    "import arrow\n",
    "import pytz\n",
    "from datetime import datetime, date, timedelta\n",
    "from timezonefinder import TimezoneFinder\n",
    "from matplotlib import pyplot as plt, dates\n",
    "from matplotlib.ticker import *\n",
    "from matplotlib_helper import *\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "M_PUBLIC_CLOUD_LOCATION = {\n",
    "    ('AWS', 'us-west-1'): (37.00578, -121.56828),\n",
    "    ('AWS', 'us-west-2'): (45.840410, -119.289460),\n",
    "    ('AWS', 'us-east-1'): (39.983334, -82.983330),\n",
    "    ('AWS', 'us-east-2'): (39.040283, -77.485165),\n",
    "    ('Azure', 'eastus'):            (37.3719, -79.8164),\n",
    "    ('Azure', 'eastus2'):           (36.6681, -78.3889),\n",
    "    ('Azure', 'southcentralus'):    (29.4167, -98.5),\n",
    "    ('Azure', 'westus2'):           (47.233, -119.852),\n",
    "    ('Azure', 'westus3'):           (33.448376, -112.074036),\n",
    "    ('Azure', 'centralus'):         (41.5908, -93.6208),\n",
    "    ('Azure', 'eastus2euap'):       (36.6681, -78.3889),\n",
    "    ('Azure', 'northcentralus'):    (41.8819, -87.6278),\n",
    "    ('Azure', 'westus'):            (37.783, -122.417),\n",
    "    ('Azure', 'centraluseuap'):     (41.5908, -93.6208),\n",
    "    ('Azure', 'westcentralus'):     (40.890, -110.234),\n",
    "}\n",
    "def get_location_for_public_cloud(cloud_vendor, region):\n",
    "    '''Looks up the GPS coordinate for public cloud region.'''\n",
    "    if (cloud_vendor, region) in M_PUBLIC_CLOUD_LOCATION:\n",
    "        return M_PUBLIC_CLOUD_LOCATION[(cloud_vendor, region)]\n",
    "    else:\n",
    "        return (math.nan, math.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_timeseries(data_array, plot_axis=None, timestamp_column_name='timestamp', prefix=None, use_relative_time=False, color=None, index=0):\n",
    "    x = [entry[timestamp_column_name] for entry in data_array]\n",
    "    if use_relative_time:\n",
    "        start_time = x[0]\n",
    "        x = [(t - start_time).total_seconds() for t in x]\n",
    "    data_keys = []\n",
    "    for key in data_array[0].keys():\n",
    "        if key == timestamp_column_name:\n",
    "            continue\n",
    "        data_keys.append(key)\n",
    "    lines = []\n",
    "    for key in data_keys:\n",
    "        data_series = [entry[key] for entry in data_array]\n",
    "        label = (('%s - ' % prefix if prefix else '') + key) if len(data_keys) > 1 else (prefix if prefix else '')\n",
    "        if plot_axis is None:\n",
    "            plot_axis = plt.gca()\n",
    "        line = plot_axis.plot(x, data_series, color=color, linestyle=get_linestyle(index), label=label, marker=None)\n",
    "        index += 1\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cdf_array(array, label, include_count = False, index=0, color=None):\n",
    "    x = sorted(array)\n",
    "    y = np.linspace(0., 1., len(array) + 1)[1:]\n",
    "    if include_count:\n",
    "        label += ' (%d)' % len(array)\n",
    "    if color is None:\n",
    "        color = get_next_color()\n",
    "    plt.plot(x, y, label=label, color=color, linestyle=get_linestyle(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def call_sysnet_carbon_api(cloud_vendor: str, region: str, start: arrow.Arrow, end: arrow.Arrow):\n",
    "    url_get_carbon_intensity = 'http://yeti-09.sysnet.ucsd.edu/carbon-intensity/'\n",
    "    (latitude, longitude) = get_location_for_public_cloud(cloud_vendor, region)\n",
    "    response = requests.get(url_get_carbon_intensity, params={\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "    })\n",
    "    assert response.ok, \"Carbon intensity lookup failed (%d): %s\" % (response.status_code, response.text)\n",
    "    response_json = response.json()\n",
    "    electricity_region = response_json['region']\n",
    "    print('region:', electricity_region)\n",
    "    carbon_intensities = response_json['carbon_intensities']\n",
    "    data_for_plot = []\n",
    "    print(carbon_intensities[0], carbon_intensities[-1])\n",
    "    for element in carbon_intensities:\n",
    "        timestamp = arrow.get(element['timestamp']).datetime\n",
    "        carbon_intensity = float(element['carbon_intensity'])\n",
    "        data_for_plot.append({\n",
    "            'timestamp': timestamp,\n",
    "            'carbon_intensity': carbon_intensity,\n",
    "        })\n",
    "    return {\n",
    "        'iso': electricity_region,\n",
    "        'data': data_for_plot,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def call_gsf_carbon_api(cloud_vendor: str, region: str, start: arrow.Arrow, end: arrow.Arrow):\n",
    "    url_get_carbon_intensity = 'https://carbon-aware-api.azurewebsites.net/emissions/bylocations'\n",
    "    response = requests.get(url_get_carbon_intensity, params={\n",
    "        'location': [region],\n",
    "        'time': start,\n",
    "        'toTime': end,\n",
    "    })\n",
    "    assert response.ok, \"GSF carbon intensity lookup failed (%d): %s\" % (response.status_code, response.text)\n",
    "    response_json = response.json()\n",
    "\n",
    "    locations = set()\n",
    "    data_for_plot = []\n",
    "    for entry in response_json:\n",
    "        locations.add(entry['location'])\n",
    "        timestamp = arrow.get(entry['time']).datetime\n",
    "        carbon_intensity = float(entry['rating'])\n",
    "        duration = entry['duration']\n",
    "        data_for_plot.append({\n",
    "            'timestamp': timestamp,\n",
    "            'carbon_intensity': carbon_intensity,\n",
    "        })\n",
    "    print('region:', locations)\n",
    "    print(data_for_plot[0], data_for_plot[-1])\n",
    "    return {\n",
    "        'iso': ','.join(locations),\n",
    "        'data': data_for_plot,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_carbon_intensity_data(cloud_vendor, region, date:date = None, timerange:timedelta = timedelta(weeks=1), use_utc_time_of_day = True):\n",
    "    print(cloud_vendor, region)\n",
    "    (latitude, longitude) = get_location_for_public_cloud(cloud_vendor, region)\n",
    "    if date is None:\n",
    "        date = arrow.get().shift(weeks=-1).date()\n",
    "    if use_utc_time_of_day:\n",
    "        timezone = pytz.UTC\n",
    "    else:\n",
    "        timezone_str = TimezoneFinder().timezone_at(lng=longitude, lat=latitude)\n",
    "        timezone = pytz.timezone(timezone_str)\n",
    "    date = arrow.get(date, tzinfo=timezone)\n",
    "    # print(timezone_str, date, file=sys.stderr)\n",
    "    if cloud_vendor == 'AWS':\n",
    "        return call_sysnet_carbon_api(cloud_vendor, region, date, date.shift(minutes=-1) + timerange)\n",
    "    elif cloud_vendor == 'Azure':\n",
    "        return call_gsf_carbon_api(cloud_vendor, region, date, date.shift(minutes=-1) + timerange)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported region {cloud_vendor}:{region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_carbon_intensity_stats(l_time_series: List[dict]):\n",
    "    l_carbon_intensity = [e['carbon_intensity'] for e in l_time_series]\n",
    "    print('Avg/Min/Max carbon intensity: %.2f/%.2f/%.2f' % (\n",
    "        np.mean(l_carbon_intensity),\n",
    "        np.min(l_carbon_intensity),\n",
    "        np.max(l_carbon_intensity),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_overlap_diff_of_carbon_intensities(time_series_1: List[dict], time_series_2: List[dict]) -> List[float]:\n",
    "    s1_timestamps = [e['timestamp'] for e in time_series_1]\n",
    "    s2_timestamps = [e['timestamp'] for e in time_series_2]\n",
    "    union_timestamps = sorted(list(set(s1_timestamps).union(s2_timestamps)))\n",
    "    # Same index as common_timestamps\n",
    "    l1_carbon_intensity = []\n",
    "    l2_carbon_intensity = []\n",
    "    l_diff_carbon_intensity = []\n",
    "    for index in range(len(union_timestamps)):\n",
    "        curr_timestamp = union_timestamps[index]\n",
    "        if curr_timestamp in s1_timestamps:\n",
    "            index1 = s1_timestamps.index(curr_timestamp)\n",
    "        else:   # Find the previous timestamp and use that\n",
    "            index1 = max(bisect.bisect(s1_timestamps, curr_timestamp) - 1, 0)\n",
    "        if curr_timestamp in s2_timestamps:\n",
    "            index2 = s2_timestamps.index(curr_timestamp)\n",
    "        else:\n",
    "            index2 = max(bisect.bisect(s2_timestamps, curr_timestamp) - 1, 0)\n",
    "        carbon_intensity1 = time_series_1[index1]['carbon_intensity']\n",
    "        carbon_intensity2 = time_series_2[index2]['carbon_intensity']\n",
    "        l1_carbon_intensity.append(carbon_intensity1)\n",
    "        l2_carbon_intensity.append(carbon_intensity2)\n",
    "        l_diff_carbon_intensity.append(carbon_intensity2 - carbon_intensity1)\n",
    "    return l_diff_carbon_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_overlap_interval_of_carbon_intensities(time_series_1: List[dict], time_series_2: List[dict]) -> \\\n",
    "        List[tuple[datetime, datetime]]:\n",
    "    \"\"\"Find the intervals where carbon intensity of the first time series drops below the second.\"\"\"\n",
    "    print(\"Finding overlap in intervals\")\n",
    "    s1_timestamps = sorted([e['timestamp'] for e in time_series_1])\n",
    "    s2_timestamps = sorted([e['timestamp'] for e in time_series_2])\n",
    "    union_timestamps = sorted(list(set(s1_timestamps).union(s2_timestamps)))\n",
    "    # Same index as common_timestamps\n",
    "    l1_carbon_intensity: List[float] = []\n",
    "    l2_carbon_intensity: List[float] = []\n",
    "    overlap_intervals: List[tuple[datetime, datetime]] = []\n",
    "    interval_start_index = None\n",
    "    for index in range(len(union_timestamps)):\n",
    "        curr_timestamp = union_timestamps[index]\n",
    "        index1 = max(bisect.bisect(s1_timestamps, curr_timestamp) - 1, 0)\n",
    "        index2 = max(bisect.bisect(s2_timestamps, curr_timestamp) - 1, 0)\n",
    "        carbon_intensity1 = time_series_1[index1]['carbon_intensity']\n",
    "        carbon_intensity2 = time_series_2[index2]['carbon_intensity']\n",
    "        l1_carbon_intensity.append(carbon_intensity1)\n",
    "        l2_carbon_intensity.append(carbon_intensity2)\n",
    "        if carbon_intensity1 <= carbon_intensity2:\n",
    "            if interval_start_index is None:\n",
    "                interval_start_index = index\n",
    "        else:\n",
    "            if interval_start_index is not None:\n",
    "                timestamp_start = union_timestamps[interval_start_index]\n",
    "                timestamp_end = union_timestamps[index]\n",
    "                overlap_intervals.append((timestamp_start, timestamp_end))\n",
    "                interval_start_index = None\n",
    "    print(\"done\")\n",
    "    return overlap_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_overlap_interval_cdf(overlap_intervals: List[tuple[datetime, datetime]], label: str) -> None:\n",
    "    interval_deltas = [(interval[1] - interval[0]) for interval in overlap_intervals]\n",
    "    interval_in_hours = [delta.total_seconds() / timedelta(hours=1).total_seconds() for delta in interval_deltas]\n",
    "    plot_cdf_array(interval_in_hours, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_cloud_region_name(cloud_region: tuple[str, str], iso: str) -> str:\n",
    "    \"\"\"Format the name for a cloud region, including its electricity-sourcing ISO.\"\"\"\n",
    "    return f'{cloud_region[0]} {cloud_region[1]} ({iso})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_utc_time_of_day = True\n",
    "enable_plot_time_series = True\n",
    "enable_overlap_analysis = True\n",
    "enable_savefig = False\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "all_cloud_vendor_and_regions = [\n",
    "    # ('AWS', 'us-west-1'),\n",
    "    # ('AWS', 'us-west-2'),\n",
    "    # ('AWS', 'us-east-1'),\n",
    "    # AWS us-east-2 uses the same ISO as us-east-1\n",
    "    # ('AWS', 'us-east-2'),\n",
    "    \n",
    "    # US regions\n",
    "    \n",
    "    # ('Azure', 'eastus'),\n",
    "    ('Azure', 'eastus2'),\n",
    "    ('Azure', 'westus'),\n",
    "    ('Azure', 'westus2'),\n",
    "    ('Azure', 'westus3'),\n",
    "    ('Azure', 'centralus'),\n",
    "    ('Azure', 'westcentralus'),\n",
    "    # ('Azure', 'northcentralus'),\n",
    "    ('Azure', 'southcentralus'),\n",
    "    # ('Azure', 'brazilsouth'),\n",
    "    ('Azure', 'canadaeast'),\n",
    "    ('Azure', 'canadacentral'),\n",
    "]\n",
    "\n",
    "stepsize = timedelta(days=365)\n",
    "for offset in range(1):\n",
    "    target_date = arrow.get(datetime(2022, 6, 1)) + (stepsize * -(1 + offset))\n",
    "    start_date = target_date\n",
    "    end_date = start_date + stepsize\n",
    "    print(f'\\n{stepsize.days}-day starting {target_date.strftime(\"%Y-%m-%d\")}')\n",
    "    plt.figure(figsize=(12, 4.8))\n",
    "    all_region_time_series_data = {}\n",
    "    for (cloud_vendor, region) in all_cloud_vendor_and_regions:\n",
    "        carbon_intensity_data = get_carbon_intensity_data(cloud_vendor, region, date=target_date, timerange=stepsize, use_utc_time_of_day=use_utc_time_of_day)\n",
    "        all_region_time_series_data[(cloud_vendor, region)] = carbon_intensity_data\n",
    "        time_series_data = carbon_intensity_data['data']\n",
    "        print(len(time_series_data))\n",
    "        if enable_plot_time_series:\n",
    "            print(\"plotting time series\")\n",
    "            # sampled_data = sorted(random.sample(time_series_data, min(len(time_series_data), 1000)), key=lambda e: e['timestamp'])\n",
    "            sampled_data = time_series_data\n",
    "            plot_timeseries(sampled_data, use_relative_time=False, prefix=f'{cloud_vendor} {region} ({carbon_intensity_data[\"iso\"]})')\n",
    "            print(\"done\")\n",
    "        print_carbon_intensity_stats(time_series_data)\n",
    "    if enable_plot_time_series:\n",
    "        if stepsize.total_seconds() == timedelta(days=1).total_seconds():\n",
    "            date_formatter_string = \"%H:%M\"\n",
    "            xlabel = f'Time of day ({\"UTC\" if use_utc_time_of_day else \"local\"})'\n",
    "        else:\n",
    "            date_formatter_string = \"%Y/%m/%d\"\n",
    "            xlabel = 'Date'\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(dates.DateFormatter(date_formatter_string))\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel('Carbon intensity (gCO2/kWh)')\n",
    "        plt.title(f'{stepsize.days}-day carbon intensity of {cloud_vendor} {region} in [{start_date.strftime(\"%Y-%m-%d\")}, {end_date.strftime(\"%Y-%m-%d\")})')\n",
    "        # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=4)\n",
    "        plt.xticks(rotation=15)\n",
    "        plt.ylim(0, 1000)\n",
    "        plt.tight_layout()\n",
    "        savefig_filename = 'carbon-intensity.%s.%ddays.png' % (target_date.strftime(\"%Y-%m-%d\"), stepsize.days)\n",
    "        if enable_savefig:\n",
    "            plt.savefig(savefig_filename)\n",
    "    if enable_overlap_analysis:\n",
    "        plt.figure()\n",
    "        # plt.figure(figsize=(5, 4))\n",
    "        cloud_region_pairs = [\n",
    "            (('AWS', 'us-west-2'), ('AWS', 'us-west-1')),\n",
    "            (('AWS', 'us-west-2'), ('AWS', 'us-east-1'))\n",
    "        ]\n",
    "        for (cloud_region1, cloud_region2) in cloud_region_pairs:\n",
    "            carbon_data1 = all_region_time_series_data[cloud_region1]\n",
    "            carbon_data2 = all_region_time_series_data[cloud_region2]\n",
    "            region1_name = format_cloud_region_name(cloud_region1, carbon_data1['iso'])\n",
    "            region2_name = format_cloud_region_name(cloud_region2, carbon_data2['iso'])\n",
    "            overlap_intervals = find_overlap_interval_of_carbon_intensities(carbon_data1['data'],\n",
    "                                                                            carbon_data2['data'])\n",
    "            print(\"plotting CDF\")\n",
    "            plot_overlap_interval_cdf(overlap_intervals, f'{region1_name} < {region2_name}')\n",
    "            print(\"done\")\n",
    "        plt.xlabel('Overlap (hours)')\n",
    "        plt.ylabel('CDF')\n",
    "        plt.title('Carbon intensity overlap in [%s,%s)' % (start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "        plt.tight_layout()\n",
    "        savefig_filename = 'carbon-intensity.overlap.%s.%ddays.pdf' % (target_date.strftime(\"%Y-%m-%d\"), stepsize.days)\n",
    "        if enable_savefig:\n",
    "            plt.savefig(savefig_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c686f18b94c7ac93143553ca22fc47dddb45e62f4fa825973de80c268de3ec5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
